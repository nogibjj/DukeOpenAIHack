{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Time\": \"12:00\",\n",
      "    \"Event\": \"13\",\n",
      "    \"Action\": \"0\",\n",
      "    \"Player\": \"None\",\n",
      "    \"Team\": \"None None\",\n",
      "    \"Description\": \"None\",\n",
      "    \"Score\": \"None\\nTime: 0:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# Read the text file\n",
    "with open(\"../data/game_play.txt\", 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Define a pattern to match key-value pairs in the text\n",
    "pattern = r'(\\w+): ([^,]+),\\s*'\n",
    "\n",
    "# Use regular expressions to find key-value pairs and store them in a dictionary\n",
    "matches = re.findall(pattern, text)\n",
    "data_dict = {key: value for key, value in matches}\n",
    "\n",
    "# Convert the dictionary to JSON\n",
    "json_data = json.dumps(data_dict, indent=4)\n",
    "\n",
    "# Print or save the JSON data\n",
    "print(json_data)\n",
    "\n",
    "# If you want to save the JSON data to a file, you can do the following:\n",
    "# with open('data.json', 'w') as json_file:\n",
    "#     json_file.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process JSON data file line by line\n",
    "\n",
    "def get_current_game_play():\n",
    "    with open(\"../data/play_by_play.json\", \"r\") as data_file:\n",
    "        for line in data_file:\n",
    "            game_play_data = json.loads(line)\n",
    "            return(game_play_data)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "import json\n",
    "\n",
    "with open(\"../api_keys.json\", 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    api_key = config.get('api_key', '')\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "def current_game_event(curr_event):\n",
    "    event_description = openai.ChatCompletion.create(\n",
    "                                                    model=\"gpt-3.5-turbo\",\n",
    "                                                    messages=[\n",
    "                                                        {\n",
    "                                                        \"role\": \"system\",\n",
    "                                                        \"content\": \"describe this as an event happening\"\n",
    "                                                        },\n",
    "                                                        {\n",
    "                                                        \"role\": \"user\",\n",
    "                                                        \"content\": f\"{curr_event}\"\n",
    "                                                        }\n",
    "                                                    ],\n",
    "                                                    temperature=1,\n",
    "                                                    max_tokens=256,\n",
    "                                                    top_p=1,\n",
    "                                                    frequency_penalty=0,\n",
    "                                                    presence_penalty=0\n",
    "                                                    )\n",
    "    return event_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 11:44 in the game, an event occurred involving player Daniel Theis from the Boston Celtics. The event was a rebound by Theis, with the rebound count showing an offensive rebound of 0 and a defensive rebound of 1. The score remains unchanged.\n"
     ]
    }
   ],
   "source": [
    "test = get_current_game_play()\n",
    "test2 = current_game_event(test[3])\n",
    "print(test2[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import json \n",
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# read openai api\n",
    "with open(\"../api_keys.json\", 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    api_key = config.get('api_key', '')\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Initialize the OpenAIEmbeddings instance\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=embeddings\n",
    "\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x124373a00>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FAISS' object has no attribute 'get_texts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# Initialize the FAISS vector store with pre-trained embeddings\u001b[39;00m\n\u001b[1;32m     18\u001b[0m vector_store \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39mfrom_texts(texts\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mYour text data goes here\u001b[39m\u001b[39m\"\u001b[39m], embedding\u001b[39m=\u001b[39membeddings)\n\u001b[0;32m---> 20\u001b[0m \u001b[39mprint\u001b[39m(vector_store\u001b[39m.\u001b[39;49mget_texts[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FAISS' object has no attribute 'get_texts'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import json\n",
    "import openai\n",
    "\n",
    "# Load your OpenAI API key from a JSON file\n",
    "with open(\"../api_keys.json\", 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    api_key = config.get('api_key', '')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the OpenAIEmbeddings instance\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "# Initialize the FAISS vector store with pre-trained embeddings\n",
    "vector_store = FAISS.\n",
    "\n",
    "print(vector_store.get_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FAISS.__init__() missing 4 required positional arguments: 'embedding_function', 'index', 'docstore', and 'index_to_docstore_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m FAISS\n\u001b[1;32m      3\u001b[0m \u001b[39m# Initialize the FAISS vector store\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m vector_store \u001b[39m=\u001b[39m FAISS()\n\u001b[1;32m      6\u001b[0m \u001b[39m# Add 5 chunks of information to the vector store\u001b[39;00m\n\u001b[1;32m      7\u001b[0m chunks \u001b[39m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mChunk 1: This is the first chunk of information.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mChunk 2: Here\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms the second chunk of data.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mChunk 5: This is the final chunk in the store.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: FAISS.__init__() missing 4 required positional arguments: 'embedding_function', 'index', 'docstore', and 'index_to_docstore_id'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Initialize the FAISS vector store\n",
    "vector_store = FAISS()\n",
    "\n",
    "# Add 5 chunks of information to the vector store\n",
    "chunks = [\n",
    "    \"Chunk 1: This is the first chunk of information.\",\n",
    "    \"Chunk 2: Here's the second chunk of data.\",\n",
    "    \"Chunk 3: Adding another chunk for demonstration.\",\n",
    "    \"Chunk 4: The fourth chunk is here.\",\n",
    "    \"Chunk 5: This is the final chunk in the store.\",\n",
    "]\n",
    "\n",
    "for chunk in chunks:\n",
    "    vector_store.add_text(chunk)\n",
    "\n",
    "# Retrieve the last 2 chunks from the vector store\n",
    "last_n_chunks = vector_store.docstore.get_texts(n=2)\n",
    "\n",
    "# Print the last 2 chunks\n",
    "for i, chunk in enumerate(last_n_chunks, start=len(chunks) - 1):\n",
    "    print(f\"Chunk {i + 1}: {chunk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'faiss' has no attribute 'DocumentStore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Create an example docstore\u001b[39;00m\n\u001b[1;32m      5\u001b[0m documents \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m      6\u001b[0m     [\u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m],\n\u001b[1;32m      7\u001b[0m     [\u001b[39m0.4\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.6\u001b[39m],\n\u001b[1;32m      8\u001b[0m     [\u001b[39m0.7\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m0.9\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Add more data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m ], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 12\u001b[0m docstore \u001b[39m=\u001b[39m faiss\u001b[39m.\u001b[39;49mDocumentStore(\u001b[39m3\u001b[39m)  \u001b[39m# 3 is the dimension of your vectors\u001b[39;00m\n\u001b[1;32m     13\u001b[0m docstore\u001b[39m.\u001b[39madd_data(documents)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Create an example index (IndexFlatL2)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'faiss' has no attribute 'DocumentStore'"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Create an example docstore\n",
    "documents = np.array([\n",
    "    [0.1, 0.2, 0.3],\n",
    "    [0.4, 0.5, 0.6],\n",
    "    [0.7, 0.8, 0.9],\n",
    "    # Add more data\n",
    "], dtype=np.float32)\n",
    "\n",
    "docstore = faiss.DocumentStore(3)  # 3 is the dimension of your vectors\n",
    "docstore.add_data(documents)\n",
    "\n",
    "# Create an example index (IndexFlatL2)\n",
    "index = faiss.IndexFlatL2(3)  # 3 is the dimension of your vectors\n",
    "\n",
    "# Add data to the index\n",
    "index.add(documents)\n",
    "\n",
    "# Perform a similarity search\n",
    "query_vector = np.array([0.2, 0.3, 0.4], dtype=np.float32)\n",
    "k = 5  # Number of similar items to retrieve\n",
    "\n",
    "# Search for similar items\n",
    "distances, indices = index.search(query_vector.reshape(1, -1), k)\n",
    "\n",
    "# Print the results\n",
    "print(\"Query Vector:\", query_vector)\n",
    "print(\"Similar Indices:\", indices[0])\n",
    "print(\"Distances:\", distances[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4591010bd32ef6a3366021e3758688a177b830536610f0989f4184bea471bd58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
